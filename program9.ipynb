{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Program 9\n",
        "\n",
        "Perceptron- Hebb's rule or Delta rule"
      ],
      "metadata": {
        "id": "TaAYVjerby5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Activation Function\n",
        "def step_function(net):\n",
        "    return 1 if net >= 0 else 0\n",
        "\n",
        "# Dataset: OR logic gate\n",
        "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "Y = np.array([0, 1, 1, 1])\n",
        "\n",
        "# 1. Hebbian Learning Rule\n",
        "def hebb_rule(X, Y):\n",
        "    weights = np.zeros(X.shape[1])\n",
        "    bias = 0\n",
        "    for i in range(len(X)):\n",
        "        weights += X[i] * Y[i]\n",
        "        bias += Y[i]\n",
        "    return weights, bias\n",
        "\n",
        "# 2. Delta Rule (Perceptron Learning)\n",
        "def delta_rule(X, Y, learning_rate=0.1, epochs=10):\n",
        "    weights = np.zeros(X.shape[1])\n",
        "    bias = 0\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(len(X)):\n",
        "            net = np.dot(X[i], weights) + bias\n",
        "            output = step_function(net)\n",
        "            error = Y[i] - output\n",
        "            weights += learning_rate * error * X[i]\n",
        "            bias += learning_rate * error\n",
        "    return weights, bias\n",
        "\n",
        "# Main Program\n",
        "print(\"Training with Hebb's Rule\")\n",
        "w_hebb, b_hebb = hebb_rule(X, Y)\n",
        "print(\"Weights:\", w_hebb, \"Bias:\", b_hebb)\n",
        "\n",
        "print(\"\\nTraining with Delta Rule\")\n",
        "w_delta, b_delta = delta_rule(X, Y)\n",
        "print(\"Weights:\", w_delta, \"Bias:\", b_delta)\n",
        "\n",
        "# Testing\n",
        "def test(X, weights, bias):\n",
        "    print(\"\\nTesting:\")\n",
        "    for x in X:\n",
        "        output = step_function(np.dot(x, weights) + bias)\n",
        "        print(f\"Input: {x}, Output: {output}\")\n",
        "\n",
        "print(\"\\n--- Hebb's Rule Output ---\")\n",
        "test(X, w_hebb, b_hebb)\n",
        "\n",
        "print(\"\\n--- Delta Rule Output ---\")\n",
        "test(X, w_delta, b_delta)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXn6H_93bzE3",
        "outputId": "c193899c-1a9b-437a-c955-782f6e7c304a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with Hebb's Rule\n",
            "Weights: [2. 2.] Bias: 3\n",
            "\n",
            "Training with Delta Rule\n",
            "Weights: [0.1 0.1] Bias: -0.1\n",
            "\n",
            "--- Hebb's Rule Output ---\n",
            "\n",
            "Testing:\n",
            "Input: [0 0], Output: 1\n",
            "Input: [0 1], Output: 1\n",
            "Input: [1 0], Output: 1\n",
            "Input: [1 1], Output: 1\n",
            "\n",
            "--- Delta Rule Output ---\n",
            "\n",
            "Testing:\n",
            "Input: [0 0], Output: 0\n",
            "Input: [0 1], Output: 1\n",
            "Input: [1 0], Output: 1\n",
            "Input: [1 1], Output: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iqjL6CWccGk4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}